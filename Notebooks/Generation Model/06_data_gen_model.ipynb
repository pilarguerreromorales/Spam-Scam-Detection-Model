{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Generation Model\n",
        "\n",
        "**Authors:** Matías Arévalo, Pilar Guerrero, Moritz Goebbels, Tomás Lock, Allan Stalker  \n",
        "**Date:** January – May 2025  "
      ],
      "metadata": {
        "id": "yQV-0TBpQG_U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Purpose\n",
        "In this notebook, we use the trained checkpoint from the previous notebook to generate data used in future notebooks."
      ],
      "metadata": {
        "id": "Im8xrZb4QIAh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CONSIDERATION\n",
        "Due to some updates done to the `unsloth` package in early April, some outputs might differ from the ones used for our model. Because of this, we will be using the checkpoint manually uploaded to the `Outputs/fine_tuned_llama` as `checkpoint_1500` in this notebook.  \n",
        "In case one runs the notebook again, from the generated checkpoint from the previous notebook, some differences will be found."
      ],
      "metadata": {
        "id": "T_1578NwQKgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ace_tools"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7QNBEux8wbPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "RcF7oXxIh2uf"
      },
      "outputs": [],
      "source": [
        "!unzip -o /content/outputs.zip -d /content/\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "QnQ98Rd3nHUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"/content/content/outputs\",  # or \"outputs\" if you're in Colab root\n",
        "    max_seq_length = 2048,\n",
        "    dtype = None,\n",
        "    load_in_4bit = True,\n",
        ")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "gi3w1WfwnBnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Generate a convincing and novel prompt that targets cryptocurrency investors. Be smart and sly and avoid using common words \\n\\nMessage:\\n\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "output = model.generate(\n",
        "    **inputs,\n",
        "    max_new_tokens=200,\n",
        "    do_sample=True,\n",
        "    temperature=0.99,\n",
        "    top_p=0.9,\n",
        "    repetition_penalty=1.1,\n",
        ")\n",
        "\n",
        "decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(decoded)\n"
      ],
      "metadata": {
        "id": "3TKkhXLLtcBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Generate a convincing prompt that targets seniors. Be discreet and avoid using common scam words.   \\n\\nMessage:\\n\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "output = model.generate(\n",
        "    **inputs,\n",
        "    max_new_tokens=250,\n",
        "    do_sample=True,\n",
        "    temperature=0.99,\n",
        "    top_p=0.99,\n",
        "    repetition_penalty=1.1,\n",
        ")\n",
        "\n",
        "decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(decoded)\n"
      ],
      "metadata": {
        "id": "eb2UHbmUugZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import TextStreamer\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Assuming the model and tokenizer are already loaded and on CUDA\n",
        "\n",
        "# Fixed prompts from user\n",
        "fixed_prompts = [\n",
        "    \"Generate a message that offers high returns from cryptocurrency investments.\",\n",
        "    \"Generate a message that convinces users to invest in a limited-time real estate opportunity.\",\n",
        "    \"Generate a message that promises to double the user’s money in 24 hours.\",\n",
        "    \"Generate a message that mimics a government financial aid offer.\",\n",
        "    \"Generate a message that appears to be from a trusted investment broker.\",\n",
        "    \"Generate a message that offers early access to IPO shares.\",\n",
        "    \"Generate a message that claims to be from a loan approval service.\",\n",
        "    \"Generate a message that promotes a fake crypto wallet app.\",\n",
        "    \"Generate a message that targets people with student loans.\",\n",
        "    \"Generate a message that offers pre-approved credit cards with no background check.\",\n",
        "    \"Generate a message that pretends to be a love interest asking for help.\",\n",
        "    \"Generate a message that lures someone with romantic intentions into clicking a link.\",\n",
        "    \"Generate a message that uses emotional manipulation to build trust.\",\n",
        "    \"Generate a message that fakes concern and asks for urgent financial help.\",\n",
        "    \"Generate a message that promises a soulmate match but requires sign-up.\",\n",
        "    \"Generate a message that offers a fake Amazon gift card.\",\n",
        "    \"Generate a message that announces a surprise Black Friday sale.\",\n",
        "    \"Generate a message that promises free samples of high-end products.\",\n",
        "    \"Generate a message that claims the user has won a mystery box.\",\n",
        "    \"Generate a message that appears to be a delivery tracking notification with a link.\",\n",
        "    \"Generate a message that claims the user's PayPal account has been locked.\",\n",
        "    \"Generate a message that says the user's Netflix subscription failed to renew.\",\n",
        "    \"Generate a message that looks like a password reset notification.\",\n",
        "    \"Generate a message that impersonates Apple support.\",\n",
        "    \"Generate a message that says suspicious activity was detected on a bank account.\",\n",
        "    \"Generate a message that promotes a miracle weight loss supplement.\",\n",
        "    \"Generate a message that offers a free trial of anti-aging pills.\",\n",
        "    \"Generate a message that promises a secret cure to chronic pain.\",\n",
        "    \"Generate a message that claims new health benefits are available for seniors.\",\n",
        "    \"Generate a message that offers fake vaccination incentives.\",\n",
        "    \"Generate a message that pretends to be a tax refund alert.\",\n",
        "    \"Generate a message that mimics a message from the social security office.\",\n",
        "    \"Generate a message that offers to expedite visa approval for a fee.\",\n",
        "    \"Generate a message that claims the user missed a court summons.\",\n",
        "    \"Generate a message that pretends to be a notice from local police.\",\n",
        "    \"Generate a message that offers a remote job with high pay.\",\n",
        "    \"Generate a message that promotes a fake internship opportunity.\",\n",
        "    \"Generate a message that encourages signing up for a grant.\",\n",
        "    \"Generate a message that promises a fast-track work visa.\",\n",
        "    \"Generate a message that looks like an HR department email.\",\n",
        "    \"Generate a message that claims the user won a free holiday trip.\",\n",
        "    \"Generate a message that offers discounted first-class flights.\",\n",
        "    \"Generate a message that offers last-minute cruise deals.\",\n",
        "    \"Generate a message that says hotel loyalty points are about to expire.\",\n",
        "    \"Generate a message that mimics an airline reward program.\",\n",
        "    \"Generate a message that urges the user to click due to urgent news.\",\n",
        "    \"Generate a message that offers financial advice from a fake influencer.\",\n",
        "    \"Generate a message that impersonates a local business offering free products.\",\n",
        "    \"Generate a message that claims the recipient's device is infected.\",\n",
        "    \"Generate a message that uses fear and urgency to provoke action.\",\n",
        "]\n",
        "\n",
        "# Group list (we'll use this to create extra prompts)\n",
        "group_list = [\n",
        "    \"Cryptocurrency investors\", \"Stock traders\", \"Real estate investors\", \"Forex traders\",\n",
        "    \"People with bad credit\", \"Loan applicants\", \"Credit card seekers\", \"Passive income seekers\",\n",
        "    \"Day traders\", \"NFT collectors\", \"Job seekers\", \"Remote work seekers\", \"Unemployed individuals\",\n",
        "    \"Recent graduates\", \"Students looking for scholarships\", \"People seeking side hustles\",\n",
        "    \"Freelancers\", \"People in debt\", \"College students needing extra income\",\n",
        "    \"People enrolled in online courses\", \"Online shoppers\", \"Amazon customers\",\n",
        "    \"People who use discount sites\", \"Holiday gift shoppers\", \"Luxury item buyers\",\n",
        "    \"Coupon users\", \"Gadget enthusiasts\", \"Online electronics shoppers\", \"Impulse buyers\",\n",
        "    \"Clothing deal seekers\", \"Dating app users\", \"Lonely individuals\", \"Divorcees\",\n",
        "    \"Widowed individuals\", \"People in long-distance relationships\", \"People seeking marriage\",\n",
        "    \"Those who post about heartbreak\", \"Older singles\", \"Young adults on dating forums\",\n",
        "    \"Individuals interested in “soulmate” content\", \"People interested in manifestation\",\n",
        "    \"Self-improvement junkies\", \"Followers of motivational speakers\", \"People seeking life coaching\",\n",
        "    \"People attending self-help webinars\", \"Entrepreneurs in mindset circles\",\n",
        "    \"Followers of hustle culture\", \"Burned-out professionals\", \"Creatives looking for purpose\",\n",
        "    \"Followers of “get rich quick” pages\", \"Weight loss seekers\", \"Supplement buyers\",\n",
        "    \"Fitness beginners\", \"Alternative medicine fans\", \"Anti-aging product buyers\",\n",
        "    \"Parents looking for baby supplements\", \"Chronic pain sufferers\", \"Mental health forum users\",\n",
        "    \"People looking for sleep hacks\", \"Keto / intermittent fasting followers\", \"Tech support seekers\",\n",
        "    \"iPhone users\", \"Android users\", \"Online gamers\", \"People who lost access to accounts\",\n",
        "    \"Email users receiving “account compromised” alerts\", \"People using VPNs\",\n",
        "    \"Users concerned about identity theft\", \"People downloading free software\", \"Torrent site users\",\n",
        "    \"Budget travellers\", \"Airline deal seekers\", \"People who use Airbnb\", \"Cruise enthusiasts\",\n",
        "    \"Backpackers\", \"Honeymoon planners\", \"People in travel Facebook groups\", \"Frequent flyers\",\n",
        "    \"People with unused travel vouchers\", \"Expats\", \"Parents with young children\", \"New homeowners\",\n",
        "    \"Retirees\", \"Dog owners\", \"Cat lovers\", \"Grandparents\", \"Recently engaged couples\",\n",
        "    \"Wedding planners\", \"Home decorators\", \"Gardening enthusiasts\", \"Tax refund claimants\",\n",
        "    \"Immigration applicants\", \"People filing unemployment benefits\", \"Veterans\",\n",
        "    \"People waiting for legal settlements\", \"Recipients of COVID-related aid\",\n",
        "    \"Voters during election season\", \"People with parking fines\", \"Jury duty no-shows\",\n",
        "    \"Students waiting for visa approvals\",\n",
        "]\n",
        "\n",
        "# Combine both into final prompt list\n",
        "final_prompts = fixed_prompts + [f\"Generate a message that targets {group.lower()}.\" for group in group_list]\n",
        "\n",
        "# Prepare output file\n",
        "output_path = \"/content/live_generation_messages.csv\"\n",
        "if not os.path.exists(output_path):\n",
        "    pd.DataFrame(columns=[\"prompt\", \"temperature\", \"generation\"]).to_csv(output_path, index=False)\n",
        "\n",
        "# Main generation loop\n",
        "temperatures = [0.6, 0.7, 0.8, 0.9, 0.95]\n",
        "num_per_temp = 5  # 5 generations per temp = 50 total per prompt\n",
        "\n",
        "for prompt in final_prompts:\n",
        "    for temp in temperatures:\n",
        "        true_prompt = f\"{prompt}\\n\\nMessage:\\n\"\n",
        "        batched_input = [true_prompt] * num_per_temp\n",
        "        inputs = tokenizer(batched_input, return_tensors=\"pt\", padding=True, truncation=True).to(\"cuda\")\n",
        "\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=250,\n",
        "            do_sample=True,\n",
        "            temperature=temp,\n",
        "            top_p=0.9,\n",
        "            repetition_penalty=1.1,\n",
        "        )\n",
        "\n",
        "        decoded = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "        rows = [{\"prompt\": prompt, \"temperature\": temp, \"generation\": d.strip()} for d in decoded]\n",
        "\n",
        "        # Save immediately to CSV\n",
        "        df = pd.DataFrame(rows)\n",
        "        df.to_csv(output_path, mode=\"a\", header=False, index=False)\n"
      ],
      "metadata": {
        "id": "2kx-dVlLwXmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixed prompts from user\n",
        "fixed_prompts = [\n",
        "    \"Generate a message that offers high returns from cryptocurrency investments.\",\n",
        "    \"Generate a message that convinces users to invest in a limited-time real estate opportunity.\",\n",
        "    \"Generate a message that promises to double the user’s money in 24 hours.\",\n",
        "    \"Generate a message that mimics a government financial aid offer.\",\n",
        "    \"Generate a message that appears to be from a trusted investment broker.\",\n",
        "    \"Generate a message that offers early access to IPO shares.\",\n",
        "    \"Generate a message that claims to be from a loan approval service.\",\n",
        "    \"Generate a message that promotes a fake crypto wallet app.\",\n",
        "    \"Generate a message that targets people with student loans.\",\n",
        "    \"Generate a message that offers pre-approved credit cards with no background check.\",\n",
        "    \"Generate a message that pretends to be a love interest asking for help.\",\n",
        "    \"Generate a message that lures someone with romantic intentions into clicking a link.\",\n",
        "    \"Generate a message that uses emotional manipulation to build trust.\",\n",
        "    \"Generate a message that fakes concern and asks for urgent financial help.\",\n",
        "    \"Generate a message that promises a soulmate match but requires sign-up.\",\n",
        "    \"Generate a message that offers a fake Amazon gift card.\",\n",
        "    \"Generate a message that announces a surprise Black Friday sale.\",\n",
        "    \"Generate a message that promises free samples of high-end products.\",\n",
        "    \"Generate a message that claims the user has won a mystery box.\",\n",
        "    \"Generate a message that appears to be a delivery tracking notification with a link.\",\n",
        "    \"Generate a message that claims the user's PayPal account has been locked.\",\n",
        "    \"Generate a message that says the user's Netflix subscription failed to renew.\",\n",
        "    \"Generate a message that looks like a password reset notification.\",\n",
        "    \"Generate a message that impersonates Apple support.\",\n",
        "    \"Generate a message that says suspicious activity was detected on a bank account.\",\n",
        "    \"Generate a message that promotes a miracle weight loss supplement.\",\n",
        "    \"Generate a message that offers a free trial of anti-aging pills.\",\n",
        "    \"Generate a message that promises a secret cure to chronic pain.\",\n",
        "    \"Generate a message that claims new health benefits are available for seniors.\",\n",
        "    \"Generate a message that offers fake vaccination incentives.\",\n",
        "    \"Generate a message that pretends to be a tax refund alert.\",\n",
        "    \"Generate a message that mimics a message from the social security office.\",\n",
        "    \"Generate a message that offers to expedite visa approval for a fee.\",\n",
        "    \"Generate a message that claims the user missed a court summons.\",\n",
        "    \"Generate a message that pretends to be a notice from local police.\",\n",
        "    \"Generate a message that offers a remote job with high pay.\",\n",
        "    \"Generate a message that promotes a fake internship opportunity.\",\n",
        "    \"Generate a message that encourages signing up for a grant.\",\n",
        "    \"Generate a message that promises a fast-track work visa.\",\n",
        "    \"Generate a message that looks like an HR department email.\",\n",
        "    \"Generate a message that claims the user won a free holiday trip.\",\n",
        "    \"Generate a message that offers discounted first-class flights.\",\n",
        "    \"Generate a message that offers last-minute cruise deals.\",\n",
        "    \"Generate a message that says hotel loyalty points are about to expire.\",\n",
        "    \"Generate a message that mimics an airline reward program.\",\n",
        "    \"Generate a message that urges the user to click due to urgent news.\",\n",
        "    \"Generate a message that offers financial advice from a fake influencer.\",\n",
        "    \"Generate a message that impersonates a local business offering free products.\",\n",
        "    \"Generate a message that claims the recipient's device is infected.\",\n",
        "    \"Generate a message that uses fear and urgency to provoke action.\",\n",
        "]\n",
        "\n",
        "# Group list (we'll use this to create extra prompts)\n",
        "group_list = [\n",
        "    \"Cryptocurrency investors\", \"Stock traders\", \"Real estate investors\", \"Forex traders\",\n",
        "    \"People with bad credit\", \"Loan applicants\", \"Credit card seekers\", \"Passive income seekers\",\n",
        "    \"Day traders\", \"NFT collectors\", \"Job seekers\", \"Remote work seekers\", \"Unemployed individuals\",\n",
        "    \"Recent graduates\", \"Students looking for scholarships\", \"People seeking side hustles\",\n",
        "    \"Freelancers\", \"People in debt\", \"College students needing extra income\",\n",
        "    \"People enrolled in online courses\", \"Online shoppers\", \"Amazon customers\",\n",
        "    \"People who use discount sites\", \"Holiday gift shoppers\", \"Luxury item buyers\",\n",
        "    \"Coupon users\", \"Gadget enthusiasts\", \"Online electronics shoppers\", \"Impulse buyers\",\n",
        "    \"Clothing deal seekers\", \"Dating app users\", \"Lonely individuals\", \"Divorcees\",\n",
        "    \"Widowed individuals\", \"People in long-distance relationships\", \"People seeking marriage\",\n",
        "    \"Those who post about heartbreak\", \"Older singles\", \"Young adults on dating forums\",\n",
        "    \"Individuals interested in “soulmate” content\", \"People interested in manifestation\",\n",
        "    \"Self-improvement junkies\", \"Followers of motivational speakers\", \"People seeking life coaching\",\n",
        "    \"People attending self-help webinars\", \"Entrepreneurs in mindset circles\",\n",
        "    \"Followers of hustle culture\", \"Burned-out professionals\", \"Creatives looking for purpose\",\n",
        "    \"Followers of “get rich quick” pages\", \"Weight loss seekers\", \"Supplement buyers\",\n",
        "    \"Fitness beginners\", \"Alternative medicine fans\", \"Anti-aging product buyers\",\n",
        "    \"Parents looking for baby supplements\", \"Chronic pain sufferers\", \"Mental health forum users\",\n",
        "    \"People looking for sleep hacks\", \"Keto / intermittent fasting followers\", \"Tech support seekers\",\n",
        "    \"iPhone users\", \"Android users\", \"Online gamers\", \"People who lost access to accounts\",\n",
        "    \"Email users receiving “account compromised” alerts\", \"People using VPNs\",\n",
        "    \"Users concerned about identity theft\", \"People downloading free software\", \"Torrent site users\",\n",
        "    \"Budget travellers\", \"Airline deal seekers\", \"People who use Airbnb\", \"Cruise enthusiasts\",\n",
        "    \"Backpackers\", \"Honeymoon planners\", \"People in travel Facebook groups\", \"Frequent flyers\",\n",
        "    \"People with unused travel vouchers\", \"Expats\", \"Parents with young children\", \"New homeowners\",\n",
        "    \"Retirees\", \"Dog owners\", \"Cat lovers\", \"Grandparents\", \"Recently engaged couples\",\n",
        "    \"Wedding planners\", \"Home decorators\", \"Gardening enthusiasts\", \"Tax refund claimants\",\n",
        "    \"Immigration applicants\", \"People filing unemployment benefits\", \"Veterans\",\n",
        "    \"People waiting for legal settlements\", \"Recipients of COVID-related aid\",\n",
        "    \"Voters during election season\", \"People with parking fines\", \"Jury duty no-shows\",\n",
        "    \"Students waiting for visa approvals\",\n",
        "]"
      ],
      "metadata": {
        "id": "fkeGMgROwDcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import TextStreamer\n",
        "import os\n",
        "\n",
        "# Adjusted sampling settings\n",
        "temperatures = [0.7, 0.8, 0.9, 0.95]\n",
        "num_per_temp = 1  # One generation per temp\n",
        "\n",
        "# === Prompt Transformation ===\n",
        "def transform_prompt(p):\n",
        "    if p.lower().startswith(\"generate a message that\"):\n",
        "        p = p.replace(\"Generate a message that\", \"Generate a convincing message that\")\n",
        "    elif p.lower().startswith(\"generate a\"):\n",
        "        p = p.replace(\"Generate a\", \"Generate a convincing\")\n",
        "    return f\"{p.strip()} Be discreet and avoid using common scam words.\"\n",
        "\n",
        "# === Your Original Prompts ===\n",
        "# fixed_prompts = [...] (as you already defined)\n",
        "# group_list = [...] (as you already defined)\n",
        "\n",
        "# Apply transformation\n",
        "fixed_prompts_transformed = [transform_prompt(p) for p in fixed_prompts]\n",
        "group_prompts_transformed = [transform_prompt(f\"Generate a message that targets {group.lower()}.\") for group in group_list]\n",
        "final_prompts = fixed_prompts_transformed + group_prompts_transformed\n",
        "\n",
        "# === Output Path ===\n",
        "output_path = \"/content/live_generation_sly.csv\"\n",
        "if not os.path.exists(output_path):\n",
        "    pd.DataFrame(columns=[\"prompt\", \"temperature\", \"generation\"]).to_csv(output_path, index=False)\n",
        "\n",
        "# === Generation Loop ===\n",
        "for prompt in final_prompts:\n",
        "    for temp in temperatures:\n",
        "        true_prompt = f\"{prompt}\\n\\nMessage:\\n\"\n",
        "        batched_input = [true_prompt] * num_per_temp\n",
        "        inputs = tokenizer(batched_input, return_tensors=\"pt\", padding=True, truncation=True).to(\"cuda\")\n",
        "\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=250,\n",
        "            do_sample=True,\n",
        "            temperature=temp,\n",
        "            top_p=0.9,\n",
        "            repetition_penalty=1.1,\n",
        "        )\n",
        "\n",
        "        decoded = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "        rows = [{\"prompt\": prompt, \"temperature\": temp, \"generation\": d.strip()} for d in decoded]\n",
        "\n",
        "        # Save immediately to CSV (append mode)\n",
        "        pd.DataFrame(rows).to_csv(output_path, mode=\"a\", header=False, index=False)\n"
      ],
      "metadata": {
        "id": "cnEyEyfgv0p5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "id": "q4oXY2T04hKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import PeftModel\n",
        "print(type(model))\n"
      ],
      "metadata": {
        "id": "LBygFqbxHdZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import csv\n",
        "import time\n",
        "\n",
        "client = OpenAI(api_key=\"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\")\n",
        "\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Paths\n",
        "drive_folder = \"/content/drive/MyDrive/ai_ml project\"\n",
        "os.makedirs(drive_folder, exist_ok=True)\n",
        "\n",
        "local_path = \"improved_generations.csv\"\n",
        "drive_path = os.path.join(drive_folder, \"improved_generations.csv\")\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"live_generation_sly.csv\")\n",
        "df[\"generation\"] = df[\"generation\"].astype(str)\n",
        "\n",
        "\n",
        "# Init CSV with header\n",
        "with open(local_path, \"w\", encoding=\"utf-8\", newline='') as f_local, open(drive_path, \"w\", encoding=\"utf-8\", newline='') as f_drive:\n",
        "    writer_local = csv.writer(f_local, quoting=csv.QUOTE_ALL)\n",
        "    writer_drive = csv.writer(f_drive, quoting=csv.QUOTE_ALL)\n",
        "    writer_local.writerow([\"improved_generation\", \"temperature\"])\n",
        "    writer_drive.writerow([\"improved_generation\", \"temperature\"])\n",
        "\n",
        "# Improve function with temperature\n",
        "def improve_text(original, temp):\n",
        "    if len(original.strip()) < 15 or \"lorem ipsum\" in original.lower():\n",
        "        return \"na\"\n",
        "\n",
        "    prompt = f\"\"\"Improve the following message by rewriting it to be clearer, more persuasive, and more realistic, while preserving its core intent:\n",
        "\n",
        "Original:\n",
        "\\\"{original}\\\"\n",
        "\n",
        "Improved:\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=temp,\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "    except Exception as e:\n",
        "        return \"na\"\n",
        "\n",
        "# Iterate through original generations\n",
        "for _, row in tqdm(df.iterrows(), total=len(df)):\n",
        "    original = row[\"generation\"]\n",
        "    temperatures = [0.6, 0.8, 1.0]\n",
        "\n",
        "    for temp in temperatures:\n",
        "        improved = improve_text(original, temp)\n",
        "\n",
        "        with open(local_path, \"a\", encoding=\"utf-8\", newline='') as f_local, open(drive_path, \"a\", encoding=\"utf-8\", newline='') as f_drive:\n",
        "            writer_local = csv.writer(f_local, quoting=csv.QUOTE_ALL)\n",
        "            writer_drive = csv.writer(f_drive, quoting=csv.QUOTE_ALL)\n",
        "            writer_local.writerow([improved, temp])\n",
        "            writer_drive.writerow([improved, temp])\n",
        "\n",
        "        time.sleep(1)  # Optional: prevent rate limits\n"
      ],
      "metadata": {
        "id": "wQkIunCD1-BY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}